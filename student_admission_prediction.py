# -*- coding: utf-8 -*-
"""Student_Admission_prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UN0eSHu6a-o07mI3JpnCxBp5kCPGy8GT
"""

import numpy as np
import pandas as pd

Stud_adm=pd.read_csv('/content/drive/MyDrive/DeepLearning/Student_admission.xlsx.csv')

Stud_adm.info()

Stud_adm.isnull().sum

Stud_adm.head()

import matplotlib.pyplot as plt

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline

Stud_adm['Admission'].value_counts()

"""# Label Encoding"""

admission_df = Stud_adm.copy()

from sklearn.preprocessing import LabelEncoder

#create instance of label encoder
lab = LabelEncoder()

#perform label encoding on 'Admission' column
admission_df['Admission'] = lab.fit_transform(admission_df['Admission'])

admission_df.head()

"""#Before Upsampling"""

admission_df['Admission'].value_counts()

print(admission_df['Admission'].value_counts())

admission_df.groupby('Admission').size().plot(kind='pie',
                                       y = "Count",
                                       label = "Type",
                                       autopct='%1.1f%%')

"""# Data Augmentation
Since taget column is Unbalanced,
Regenerating new samples using Bootrapping method for biased samples
So, Divide the target features according to classes  

"""



from pickle import ADDITEMS
from sklearn.utils import resample 
adm_0 = admission_df[admission_df['Admission']==0]
adm_1 = admission_df[admission_df['Admission']==1]

"""#Upsampling

###Since the count class '0' is 2348 and class '1' is 5376, so duplicate the '0' class from existing '0' class to balance the class
###Say, class '0' requires (5376-2348) samples i.e 3028
"""

adm_0_sample = resample(adm_0,
             replace=True,
             n_samples=len(adm_1),
             random_state=42)

print(adm_0_sample.shape)

"""# Merge Upsampling class to existing class"""

data_upsampled = pd.concat([adm_0_sample, adm_1])

print(data_upsampled["Admission"].value_counts())

data_upsampled.groupby('Admission').size().plot(kind='pie',
                                       y = "v1",
                                       label = "Type",
                                       autopct='%1.1f%%')

data_upsampled.head()

data_upsampled.describe

data_upsampled.info()

admission_df1 = data_upsampled.copy()

admission_df1.info()

admission_df1['Admission'].value_counts()

"""# Feature selection
Correlation
"""

import seaborn as sns
plt.figure(figsize=(13,8))
sns.heatmap(admission_df1.corr(),annot=True, cmap="RdYlGn")

admission_df2 = admission_df1.drop(['S.No', 'Your full Name'], axis=1)

admission_df2.info()

import seaborn as sns
plt.figure(figsize=(13,8))
sns.heatmap(admission_df2.corr(),annot=True, cmap="RdYlGn")

"""# Data Preprocessing"""

x= admission_df2.drop(['Admission'], axis=1)
y=admission_df2['Admission']

x1=x.copy()
x.head()

"""# One Hot Encodeing for 'Degree' feature
BCA=0
B.Sc CS=1
B.Sc IT=2
"""

onehot_encoding = pd.get_dummies(x.Degree, prefix = 'Degree')

df = pd.concat([x, onehot_encoding], axis=1).drop('Degree', axis=1)
x1=df
x1.head()

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test = train_test_split(x1,y,test_size=0.2,random_state=32)

x_train,x_test, y_train,y_test

from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler(feature_range=(0,1))
x_train_scaler = scaler.fit_transform(x_train)
x_test_scaler = scaler.transform(x_test)

x_train_scaler

"""# Model Fitting - Classification

#Model:1 Naive Bayes Classifier
"""

# train a Gaussian Naive Bayes classifier on the training set
from sklearn.naive_bayes import GaussianNB


# instantiate the model
gnb = GaussianNB()


# fit the model
gnb.fit(x_train_scaler, y_train)

"""# Predict the Result"""

y_predict = gnb.predict(x_test_scaler)
y_predict

"""Check the Accuracy Score"""

from sklearn.metrics import accuracy_score

print('Model accuracy score: {0:0.4f}'. format(accuracy_score(y_test, y_predict)))

"""# Model:2 Decision Tree Algorithm with 100 % accuracy"""

from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split
classifier=DecisionTreeClassifier()

classifier.fit(x_train_scaler, y_train)

prediction=classifier.predict(x_test_scaler)

from sklearn.metrics import confusion_matrix,classification_report
print(confusion_matrix(y_test,prediction))
print(classification_report(y_test,prediction))

